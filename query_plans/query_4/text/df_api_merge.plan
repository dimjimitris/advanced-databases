[91mQ4: [00mQuery execution plan (1a, merge):
== Physical Plan ==
AdaptiveSparkPlan (23)
+- Sort (22)
   +- Exchange (21)
      +- HashAggregate (20)
         +- Exchange (19)
            +- HashAggregate (18)
               +- InMemoryTableScan (1)
                     +- InMemoryRelation (2)
                           +- AdaptiveSparkPlan (17)
                              +- Project (16)
                                 +- BatchEvalPython (15)
                                    +- Project (14)
                                       +- SortMergeJoin Inner (13)
                                          :- Sort (7)
                                          :  +- Exchange (6)
                                          :     +- Project (5)
                                          :        +- Filter (4)
                                          :           +- Scan csv  (3)
                                          +- Sort (12)
                                             +- Exchange (11)
                                                +- Project (10)
                                                   +- Filter (9)
                                                      +- Scan csv  (8)


(1) InMemoryTableScan
Output [2]: [Year#95, Distance to Station#188]
Arguments: [Year#95, Distance to Station#188]

(2) InMemoryRelation
Arguments: [Year#95, Division#27, Distance to Station#188], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@11e6cf7b,StorageLevel(disk, memory, deserialized, 1 replicas),AdaptiveSparkPlan isFinalPlan=false
+- Project [Year#95, Division#27, pythonUDF0#225 AS Distance to Station#188]
   +- BatchEvalPython [<lambda>(LAT#64, LON#65, Station LAT#20, Station LON#12)#187], [pythonUDF0#225]
      +- Project [LAT#64, LON#65, Year#95, Station LON#12, Station LAT#20, Division#27]
         +- SortMergeJoin [PREC#125], [PREC#5], Inner
            :- Sort [PREC#125 ASC NULLS FIRST], false, 0
            :  +- Exchange hashpartitioning(PREC#125, 200), ENSURE_REQUIREMENTS, [plan_id=33]
            :     +- Project [AREA#42 AS PREC#125, LAT#64, LON#65, year(Date Rptd#39) AS Year#95]
            :        +- Filter (((((((isnotnull(LAT#64) AND isnotnull(LON#65)) AND isnotnull(Weapon Used Cd#54)) AND NOT (LAT#64 = 0.0)) AND NOT (LON#65 = 0.0)) AND (Weapon Used Cd#54 >= 100)) AND (Weapon Used Cd#54 <= 199)) AND isnotnull(AREA#42))
            :           +- FileScan csv [Date Rptd#39,AREA#42,Weapon Used Cd#54,LAT#64,LON#65] Batched: false, DataFilters: [isnotnull(LAT#64), isnotnull(LON#65), isnotnull(Weapon Used Cd#54), NOT (LAT#64 = 0.0), NOT (LON..., Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LO..., ReadSchema: struct<Date Rptd:date,AREA:int,Weapon Used Cd:int,LAT:double,LON:double>
            +- Sort [PREC#5 ASC NULLS FIRST], false, 0
               +- Exchange hashpartitioning(PREC#5, 200), ENSURE_REQUIREMENTS, [plan_id=34]
                  +- Project [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
                     +- Filter isnotnull(PREC#5)
                        +- FileScan csv [X#0,Y#1,DIVISION#3,PREC#5] Batched: false, DataFilters: [isnotnull(PREC#5)], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv], PartitionFilters: [], PushedFilters: [IsNotNull(PREC)], ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>
,None)

(3) Scan csv 
Output [5]: [Date Rptd#39, AREA#42, Weapon Used Cd#54, LAT#64, LON#65]
Batched: false
Location: InMemoryFileIndex [hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to_Present.csv]
PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0)), GreaterThanOrEqual(Weapon Used Cd,100), LessThanOrEqual(Weapon Used Cd,199), IsNotNull(AREA)]
ReadSchema: struct<Date Rptd:date,AREA:int,Weapon Used Cd:int,LAT:double,LON:double>

(4) Filter
Input [5]: [Date Rptd#39, AREA#42, Weapon Used Cd#54, LAT#64, LON#65]
Condition : (((((((isnotnull(LAT#64) AND isnotnull(LON#65)) AND isnotnull(Weapon Used Cd#54)) AND NOT (LAT#64 = 0.0)) AND NOT (LON#65 = 0.0)) AND (Weapon Used Cd#54 >= 100)) AND (Weapon Used Cd#54 <= 199)) AND isnotnull(AREA#42))

(5) Project
Output [4]: [AREA#42 AS PREC#125, LAT#64, LON#65, year(Date Rptd#39) AS Year#95]
Input [5]: [Date Rptd#39, AREA#42, Weapon Used Cd#54, LAT#64, LON#65]

(6) Exchange
Input [4]: [PREC#125, LAT#64, LON#65, Year#95]
Arguments: hashpartitioning(PREC#125, 200), ENSURE_REQUIREMENTS, [plan_id=145]

(7) Sort
Input [4]: [PREC#125, LAT#64, LON#65, Year#95]
Arguments: [PREC#125 ASC NULLS FIRST], false, 0

(8) Scan csv 
Output [4]: [X#0, Y#1, DIVISION#3, PREC#5]
Batched: false
Location: InMemoryFileIndex [hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv]
PushedFilters: [IsNotNull(PREC)]
ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>

(9) Filter
Input [4]: [X#0, Y#1, DIVISION#3, PREC#5]
Condition : isnotnull(PREC#5)

(10) Project
Output [4]: [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
Input [4]: [X#0, Y#1, DIVISION#3, PREC#5]

(11) Exchange
Input [4]: [Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: hashpartitioning(PREC#5, 200), ENSURE_REQUIREMENTS, [plan_id=146]

(12) Sort
Input [4]: [Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: [PREC#5 ASC NULLS FIRST], false, 0

(13) SortMergeJoin
Left keys [1]: [PREC#125]
Right keys [1]: [PREC#5]
Join type: Inner
Join condition: None

(14) Project
Output [6]: [LAT#64, LON#65, Year#95, Station LON#12, Station LAT#20, Division#27]
Input [8]: [PREC#125, LAT#64, LON#65, Year#95, Station LON#12, Station LAT#20, Division#27, PREC#5]

(15) BatchEvalPython
Input [6]: [LAT#64, LON#65, Year#95, Station LON#12, Station LAT#20, Division#27]
Arguments: [<lambda>(LAT#64, LON#65, Station LAT#20, Station LON#12)#187], [pythonUDF0#225]

(16) Project
Output [3]: [Year#95, Division#27, pythonUDF0#225 AS Distance to Station#188]
Input [7]: [LAT#64, LON#65, Year#95, Station LON#12, Station LAT#20, Division#27, pythonUDF0#225]

(17) AdaptiveSparkPlan
Output [3]: [Year#95, Division#27, Distance to Station#188]
Arguments: isFinalPlan=false

(18) HashAggregate
Input [2]: [Year#95, Distance to Station#188]
Keys [1]: [Year#95]
Functions [2]: [partial_avg(Distance to Station#188), partial_count(1)]
Aggregate Attributes [3]: [sum#2036, count#2037L, count#2038L]
Results [4]: [Year#95, sum#2039, count#2040L, count#2041L]

(19) Exchange
Input [4]: [Year#95, sum#2039, count#2040L, count#2041L]
Arguments: hashpartitioning(Year#95, 200), ENSURE_REQUIREMENTS, [plan_id=138]

(20) HashAggregate
Input [4]: [Year#95, sum#2039, count#2040L, count#2041L]
Keys [1]: [Year#95]
Functions [2]: [avg(Distance to Station#188), count(1)]
Aggregate Attributes [2]: [avg(Distance to Station#188)#244, count(1)#246L]
Results [3]: [Year#95, avg(Distance to Station#188)#244 AS Average Distance to Station#245, count(1)#246L AS ##247L]

(21) Exchange
Input [3]: [Year#95, Average Distance to Station#245, ##247L]
Arguments: rangepartitioning(Year#95 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=141]

(22) Sort
Input [3]: [Year#95, Average Distance to Station#245, ##247L]
Arguments: [Year#95 ASC NULLS FIRST], true, 0

(23) AdaptiveSparkPlan
Output [3]: [Year#95, Average Distance to Station#245, ##247L]
Arguments: isFinalPlan=false



[91mQ4: [00mQuery execution plan (1b, merge):
== Physical Plan ==
AdaptiveSparkPlan (23)
+- Sort (22)
   +- Exchange (21)
      +- HashAggregate (20)
         +- Exchange (19)
            +- HashAggregate (18)
               +- InMemoryTableScan (1)
                     +- InMemoryRelation (2)
                           +- AdaptiveSparkPlan (17)
                              +- Project (16)
                                 +- BatchEvalPython (15)
                                    +- Project (14)
                                       +- SortMergeJoin Inner (13)
                                          :- Sort (7)
                                          :  +- Exchange (6)
                                          :     +- Project (5)
                                          :        +- Filter (4)
                                          :           +- Scan csv  (3)
                                          +- Sort (12)
                                             +- Exchange (11)
                                                +- Project (10)
                                                   +- Filter (9)
                                                      +- Scan csv  (8)


(1) InMemoryTableScan
Output [2]: [Division#27, Distance to Station#188]
Arguments: [Division#27, Distance to Station#188]

(2) InMemoryRelation
Arguments: [Year#95, Division#27, Distance to Station#188], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@11e6cf7b,StorageLevel(disk, memory, deserialized, 1 replicas),AdaptiveSparkPlan isFinalPlan=false
+- Project [Year#95, Division#27, pythonUDF0#225 AS Distance to Station#188]
   +- BatchEvalPython [<lambda>(LAT#64, LON#65, Station LAT#20, Station LON#12)#187], [pythonUDF0#225]
      +- Project [LAT#64, LON#65, Year#95, Station LON#12, Station LAT#20, Division#27]
         +- SortMergeJoin [PREC#125], [PREC#5], Inner
            :- Sort [PREC#125 ASC NULLS FIRST], false, 0
            :  +- Exchange hashpartitioning(PREC#125, 200), ENSURE_REQUIREMENTS, [plan_id=33]
            :     +- Project [AREA#42 AS PREC#125, LAT#64, LON#65, year(Date Rptd#39) AS Year#95]
            :        +- Filter (((((((isnotnull(LAT#64) AND isnotnull(LON#65)) AND isnotnull(Weapon Used Cd#54)) AND NOT (LAT#64 = 0.0)) AND NOT (LON#65 = 0.0)) AND (Weapon Used Cd#54 >= 100)) AND (Weapon Used Cd#54 <= 199)) AND isnotnull(AREA#42))
            :           +- FileScan csv [Date Rptd#39,AREA#42,Weapon Used Cd#54,LAT#64,LON#65] Batched: false, DataFilters: [isnotnull(LAT#64), isnotnull(LON#65), isnotnull(Weapon Used Cd#54), NOT (LAT#64 = 0.0), NOT (LON..., Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LO..., ReadSchema: struct<Date Rptd:date,AREA:int,Weapon Used Cd:int,LAT:double,LON:double>
            +- Sort [PREC#5 ASC NULLS FIRST], false, 0
               +- Exchange hashpartitioning(PREC#5, 200), ENSURE_REQUIREMENTS, [plan_id=34]
                  +- Project [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
                     +- Filter isnotnull(PREC#5)
                        +- FileScan csv [X#0,Y#1,DIVISION#3,PREC#5] Batched: false, DataFilters: [isnotnull(PREC#5)], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv], PartitionFilters: [], PushedFilters: [IsNotNull(PREC)], ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>
,None)

(3) Scan csv 
Output [5]: [Date Rptd#39, AREA#42, Weapon Used Cd#54, LAT#64, LON#65]
Batched: false
Location: InMemoryFileIndex [hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to_Present.csv]
PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0)), GreaterThanOrEqual(Weapon Used Cd,100), LessThanOrEqual(Weapon Used Cd,199), IsNotNull(AREA)]
ReadSchema: struct<Date Rptd:date,AREA:int,Weapon Used Cd:int,LAT:double,LON:double>

(4) Filter
Input [5]: [Date Rptd#39, AREA#42, Weapon Used Cd#54, LAT#64, LON#65]
Condition : (((((((isnotnull(LAT#64) AND isnotnull(LON#65)) AND isnotnull(Weapon Used Cd#54)) AND NOT (LAT#64 = 0.0)) AND NOT (LON#65 = 0.0)) AND (Weapon Used Cd#54 >= 100)) AND (Weapon Used Cd#54 <= 199)) AND isnotnull(AREA#42))

(5) Project
Output [4]: [AREA#42 AS PREC#125, LAT#64, LON#65, year(Date Rptd#39) AS Year#95]
Input [5]: [Date Rptd#39, AREA#42, Weapon Used Cd#54, LAT#64, LON#65]

(6) Exchange
Input [4]: [PREC#125, LAT#64, LON#65, Year#95]
Arguments: hashpartitioning(PREC#125, 200), ENSURE_REQUIREMENTS, [plan_id=175]

(7) Sort
Input [4]: [PREC#125, LAT#64, LON#65, Year#95]
Arguments: [PREC#125 ASC NULLS FIRST], false, 0

(8) Scan csv 
Output [4]: [X#0, Y#1, DIVISION#3, PREC#5]
Batched: false
Location: InMemoryFileIndex [hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv]
PushedFilters: [IsNotNull(PREC)]
ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>

(9) Filter
Input [4]: [X#0, Y#1, DIVISION#3, PREC#5]
Condition : isnotnull(PREC#5)

(10) Project
Output [4]: [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
Input [4]: [X#0, Y#1, DIVISION#3, PREC#5]

(11) Exchange
Input [4]: [Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: hashpartitioning(PREC#5, 200), ENSURE_REQUIREMENTS, [plan_id=176]

(12) Sort
Input [4]: [Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: [PREC#5 ASC NULLS FIRST], false, 0

(13) SortMergeJoin
Left keys [1]: [PREC#125]
Right keys [1]: [PREC#5]
Join type: Inner
Join condition: None

(14) Project
Output [6]: [LAT#64, LON#65, Year#95, Station LON#12, Station LAT#20, Division#27]
Input [8]: [PREC#125, LAT#64, LON#65, Year#95, Station LON#12, Station LAT#20, Division#27, PREC#5]

(15) BatchEvalPython
Input [6]: [LAT#64, LON#65, Year#95, Station LON#12, Station LAT#20, Division#27]
Arguments: [<lambda>(LAT#64, LON#65, Station LAT#20, Station LON#12)#187], [pythonUDF0#225]

(16) Project
Output [3]: [Year#95, Division#27, pythonUDF0#225 AS Distance to Station#188]
Input [7]: [LAT#64, LON#65, Year#95, Station LON#12, Station LAT#20, Division#27, pythonUDF0#225]

(17) AdaptiveSparkPlan
Output [3]: [Year#95, Division#27, Distance to Station#188]
Arguments: isFinalPlan=false

(18) HashAggregate
Input [2]: [Division#27, Distance to Station#188]
Keys [1]: [Division#27]
Functions [2]: [partial_avg(Distance to Station#188), partial_count(1)]
Aggregate Attributes [3]: [sum#2087, count#2088L, count#2089L]
Results [4]: [Division#27, sum#2090, count#2091L, count#2092L]

(19) Exchange
Input [4]: [Division#27, sum#2090, count#2091L, count#2092L]
Arguments: hashpartitioning(Division#27, 200), ENSURE_REQUIREMENTS, [plan_id=168]

(20) HashAggregate
Input [4]: [Division#27, sum#2090, count#2091L, count#2092L]
Keys [1]: [Division#27]
Functions [2]: [avg(Distance to Station#188), count(1)]
Aggregate Attributes [2]: [avg(Distance to Station#188)#254, count(1)#256L]
Results [3]: [Division#27, avg(Distance to Station#188)#254 AS Average Distance to Station#255, count(1)#256L AS ##257L]

(21) Exchange
Input [3]: [Division#27, Average Distance to Station#255, ##257L]
Arguments: rangepartitioning(##257L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=171]

(22) Sort
Input [3]: [Division#27, Average Distance to Station#255, ##257L]
Arguments: [##257L DESC NULLS LAST], true, 0

(23) AdaptiveSparkPlan
Output [3]: [Division#27, Average Distance to Station#255, ##257L]
Arguments: isFinalPlan=false



[91mQ4: [00mQuery execution plan (2a, merge):
== Physical Plan ==
AdaptiveSparkPlan (40)
+- Sort (39)
   +- Exchange (38)
      +- HashAggregate (37)
         +- Exchange (36)
            +- HashAggregate (35)
               +- InMemoryTableScan (1)
                     +- InMemoryRelation (2)
                           +- AdaptiveSparkPlan (34)
                              +- Project (33)
                                 +- SortMergeJoin Inner (32)
                                    :- Sort (17)
                                    :  +- Exchange (16)
                                    :     +- Filter (15)
                                    :        +- InMemoryTableScan (3)
                                    :              +- InMemoryRelation (4)
                                    :                    +- AdaptiveSparkPlan (14)
                                    :                       +- Project (13)
                                    :                          +- BatchEvalPython (12)
                                    :                             +- BroadcastNestedLoopJoin Cross BuildRight (11)
                                    :                                :- Project (7)
                                    :                                :  +- Filter (6)
                                    :                                :     +- Scan csv  (5)
                                    :                                +- BroadcastExchange (10)
                                    :                                   +- Project (9)
                                    :                                      +- Scan csv  (8)
                                    +- Sort (31)
                                       +- Exchange (30)
                                          +- Filter (29)
                                             +- HashAggregate (28)
                                                +- Exchange (27)
                                                   +- HashAggregate (26)
                                                      +- Filter (25)
                                                         +- InMemoryTableScan (18)
                                                               +- InMemoryRelation (19)
                                                                     +- AdaptiveSparkPlan (24)
                                                                        +- Project (23)
                                                                           +- BatchEvalPython (22)
                                                                              +- BroadcastNestedLoopJoin Cross BuildRight (21)
                                                                                 :- Project (7)
                                                                                 :  +- Filter (6)
                                                                                 :     +- Scan csv  (5)
                                                                                 +- BroadcastExchange (20)
                                                                                    +- Project (9)
                                                                                       +- Scan csv  (8)


(1) InMemoryTableScan
Output [2]: [Year#318, Distance to Closest Station#726]
Arguments: [Year#318, Distance to Closest Station#726]

(2) InMemoryRelation
Arguments: [Year#318, Division#27, Distance to Closest Station#726], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@11e6cf7b,StorageLevel(disk, memory, deserialized, 1 replicas),AdaptiveSparkPlan isFinalPlan=false
+- Project [Year#318, Division#27, Distance to Station#412 AS Distance to Closest Station#726]
   +- SortMergeJoin [DR_NO#261, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412))], [DR_NO#656, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653))], Inner
      :- Sort [DR_NO#261 ASC NULLS FIRST, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412)) ASC NULLS FIRST], false, 0
      :  +- Exchange hashpartitioning(DR_NO#261, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412)), 200), ENSURE_REQUIREMENTS, [plan_id=107]
      :     +- Filter (isnotnull(DR_NO#261) AND isnotnull(Distance to Station#412))
      :        +- InMemoryTableScan [DR_NO#261, Year#318, Division#27, Distance to Station#412], [isnotnull(DR_NO#261), isnotnull(Distance to Station#412)]
      :              +- InMemoryRelation [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)
      :                    +- AdaptiveSparkPlan isFinalPlan=false
      :                       +- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields]
      :                          +- BatchEvalPython [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]
      :                             +- BroadcastNestedLoopJoin BuildRight, Cross
      :                                :- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265 AS PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 5 more fields]
      :                                :  +- Filter ((((((isnotnull(LAT#287) AND isnotnull(LON#288)) AND isnotnull(Weapon Used Cd#277)) AND NOT (LAT#287 = 0.0)) AND NOT (LON#288 = 0.0)) AND (Weapon Used Cd#277 >= 100)) AND (Weapon Used Cd#277 <= 199))
      :                                :     +- FileScan csv [DR_NO#261,Date Rptd#262,DATE OCC#263,TIME OCC#264,AREA#265,AREA NAME#266,Rpt Dist No#267,Part 1-2#268,Crm Cd#269,Crm Cd Desc#270,Mocodes#271,Vict Age#272,Vict Sex#273,Vict Descent#274,Premis Cd#275,Premis Desc#276,Weapon Used Cd#277,Weapon Desc#278,Status#279,Status Desc#280,Crm Cd 1#281,Crm Cd 2#282,Crm Cd 3#283,Crm Cd 4#284,... 4 more fields] Batched: false, DataFilters: [isnotnull(LAT#287), isnotnull(LON#288), isnotnull(Weapon Used Cd#277), NOT (LAT#287 = 0.0), NOT ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LO..., ReadSchema: struct<DR_NO:int,Date Rptd:date,DATE OCC:date,TIME OCC:string,AREA:int,AREA NAME:string,Rpt Dist ...
      :                                +- BroadcastExchange IdentityBroadcastMode, [plan_id=114]
      :                                   +- Project [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
      :                                      +- FileScan csv [X#0,Y#1,DIVISION#3,PREC#5] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>
      +- Sort [DR_NO#656 ASC NULLS FIRST, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653)) ASC NULLS FIRST], false, 0
         +- Exchange hashpartitioning(DR_NO#656, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653)), 200), ENSURE_REQUIREMENTS, [plan_id=108]
            +- Filter isnotnull(Distance to Station#653)
               +- HashAggregate(keys=[DR_NO#656], functions=[min(Distance to Station#412)], output=[DR_NO#656, Distance to Station#653])
                  +- Exchange hashpartitioning(DR_NO#656, 200), ENSURE_REQUIREMENTS, [plan_id=102]
                     +- HashAggregate(keys=[DR_NO#656], functions=[partial_min(Distance to Station#412)], output=[DR_NO#656, min#1955])
                        +- Filter isnotnull(DR_NO#656)
                           +- InMemoryTableScan [DR_NO#656, Distance to Station#412], [isnotnull(DR_NO#656)]
                                 +- InMemoryRelation [DR_NO#656, Date Rptd#657, DATE OCC#658, TIME OCC#659, PREC#348, AREA NAME#661, Rpt Dist No#662, Part 1-2#663, Crm Cd#664, Crm Cd Desc#665, Mocodes#666, Vict Age#667, Vict Sex#668, Vict Descent#669, Premis Cd#670, Premis Desc#671, Weapon Used Cd#672, Weapon Desc#673, Status#674, Status Desc#675, Crm Cd 1#676, Crm Cd 2#677, Crm Cd 3#678, Crm Cd 4#679, ... 10 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)
                                       +- AdaptiveSparkPlan isFinalPlan=false
                                          +- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields]
                                             +- BatchEvalPython [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]
                                                +- BroadcastNestedLoopJoin BuildRight, Cross
                                                   :- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265 AS PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 5 more fields]
                                                   :  +- Filter ((((((isnotnull(LAT#287) AND isnotnull(LON#288)) AND isnotnull(Weapon Used Cd#277)) AND NOT (LAT#287 = 0.0)) AND NOT (LON#288 = 0.0)) AND (Weapon Used Cd#277 >= 100)) AND (Weapon Used Cd#277 <= 199))
                                                   :     +- FileScan csv [DR_NO#261,Date Rptd#262,DATE OCC#263,TIME OCC#264,AREA#265,AREA NAME#266,Rpt Dist No#267,Part 1-2#268,Crm Cd#269,Crm Cd Desc#270,Mocodes#271,Vict Age#272,Vict Sex#273,Vict Descent#274,Premis Cd#275,Premis Desc#276,Weapon Used Cd#277,Weapon Desc#278,Status#279,Status Desc#280,Crm Cd 1#281,Crm Cd 2#282,Crm Cd 3#283,Crm Cd 4#284,... 4 more fields] Batched: false, DataFilters: [isnotnull(LAT#287), isnotnull(LON#288), isnotnull(Weapon Used Cd#277), NOT (LAT#287 = 0.0), NOT ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LO..., ReadSchema: struct<DR_NO:int,Date Rptd:date,DATE OCC:date,TIME OCC:string,AREA:int,AREA NAME:string,Rpt Dist ...
                                                   +- BroadcastExchange IdentityBroadcastMode, [plan_id=119]
                                                      +- Project [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
                                                         +- FileScan csv [X#0,Y#1,DIVISION#3,PREC#5] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>
,None)

(3) InMemoryTableScan
Output [4]: [DR_NO#261, Year#318, Division#27, Distance to Station#412]
Arguments: [DR_NO#261, Year#318, Division#27, Distance to Station#412], [isnotnull(DR_NO#261), isnotnull(Distance to Station#412)]

(4) InMemoryRelation
Arguments: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@11e6cf7b,StorageLevel(disk, memory, deserialized, 1 replicas),AdaptiveSparkPlan isFinalPlan=false
+- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields]
   +- BatchEvalPython [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]
      +- BroadcastNestedLoopJoin BuildRight, Cross
         :- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265 AS PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 5 more fields]
         :  +- Filter ((((((isnotnull(LAT#287) AND isnotnull(LON#288)) AND isnotnull(Weapon Used Cd#277)) AND NOT (LAT#287 = 0.0)) AND NOT (LON#288 = 0.0)) AND (Weapon Used Cd#277 >= 100)) AND (Weapon Used Cd#277 <= 199))
         :     +- FileScan csv [DR_NO#261,Date Rptd#262,DATE OCC#263,TIME OCC#264,AREA#265,AREA NAME#266,Rpt Dist No#267,Part 1-2#268,Crm Cd#269,Crm Cd Desc#270,Mocodes#271,Vict Age#272,Vict Sex#273,Vict Descent#274,Premis Cd#275,Premis Desc#276,Weapon Used Cd#277,Weapon Desc#278,Status#279,Status Desc#280,Crm Cd 1#281,Crm Cd 2#282,Crm Cd 3#283,Crm Cd 4#284,... 4 more fields] Batched: false, DataFilters: [isnotnull(LAT#287), isnotnull(LON#288), isnotnull(Weapon Used Cd#277), NOT (LAT#287 = 0.0), NOT ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LO..., ReadSchema: struct<DR_NO:int,Date Rptd:date,DATE OCC:date,TIME OCC:string,AREA:int,AREA NAME:string,Rpt Dist ...
         +- BroadcastExchange IdentityBroadcastMode, [plan_id=67]
            +- Project [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
               +- FileScan csv [X#0,Y#1,DIVISION#3,PREC#5] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>
,None)

(5) Scan csv 
Output [28]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288]
Batched: false
Location: InMemoryFileIndex [hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to_Present.csv]
PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0)), GreaterThanOrEqual(Weapon Used Cd,100), LessThanOrEqual(Weapon Used Cd,199)]
ReadSchema: struct<DR_NO:int,Date Rptd:date,DATE OCC:date,TIME OCC:string,AREA:int,AREA NAME:string,Rpt Dist No:int,Part 1-2:string,Crm Cd:int,Crm Cd Desc:string,Mocodes:string,Vict Age:int,Vict Sex:string,Vict Descent:string,Premis Cd:int,Premis Desc:string,Weapon Used Cd:int,Weapon Desc:string,Status:string,Status Desc:string,Crm Cd 1:int,Crm Cd 2:int,Crm Cd 3:int,Crm Cd 4:int,LOCATION:string,Cross Street:string,LAT:double,LON:double>

(6) Filter
Input [28]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288]
Condition : ((((((isnotnull(LAT#287) AND isnotnull(LON#288)) AND isnotnull(Weapon Used Cd#277)) AND NOT (LAT#287 = 0.0)) AND NOT (LON#288 = 0.0)) AND (Weapon Used Cd#277 >= 100)) AND (Weapon Used Cd#277 <= 199))

(7) Project
Output [29]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265 AS PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, year(Date Rptd#262) AS Year#318]
Input [28]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288]

(8) Scan csv 
Output [4]: [X#0, Y#1, DIVISION#3, PREC#5]
Batched: false
Location: InMemoryFileIndex [hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv]
ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>

(9) Project
Output [4]: [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
Input [4]: [X#0, Y#1, DIVISION#3, PREC#5]

(10) BroadcastExchange
Input [4]: [Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: IdentityBroadcastMode, [plan_id=114]

(11) BroadcastNestedLoopJoin
Join type: Cross
Join condition: None

(12) BatchEvalPython
Input [33]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]

(13) Project
Output [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, pythonUDF0#447 AS Distance to Station#412]
Input [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, pythonUDF0#447]

(14) AdaptiveSparkPlan
Output [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, Distance to Station#412]
Arguments: isFinalPlan=false

(15) Filter
Input [4]: [DR_NO#261, Year#318, Division#27, Distance to Station#412]
Condition : (isnotnull(DR_NO#261) AND isnotnull(Distance to Station#412))

(16) Exchange
Input [4]: [DR_NO#261, Year#318, Division#27, Distance to Station#412]
Arguments: hashpartitioning(DR_NO#261, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412)), 200), ENSURE_REQUIREMENTS, [plan_id=209]

(17) Sort
Input [4]: [DR_NO#261, Year#318, Division#27, Distance to Station#412]
Arguments: [DR_NO#261 ASC NULLS FIRST, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412)) ASC NULLS FIRST], false, 0

(18) InMemoryTableScan
Output [2]: [DR_NO#656, Distance to Station#412]
Arguments: [DR_NO#656, Distance to Station#412], [isnotnull(DR_NO#656)]

(19) InMemoryRelation
Arguments: [DR_NO#656, Date Rptd#657, DATE OCC#658, TIME OCC#659, PREC#348, AREA NAME#661, Rpt Dist No#662, Part 1-2#663, Crm Cd#664, Crm Cd Desc#665, Mocodes#666, Vict Age#667, Vict Sex#668, Vict Descent#669, Premis Cd#670, Premis Desc#671, Weapon Used Cd#672, Weapon Desc#673, Status#674, Status Desc#675, Crm Cd 1#676, Crm Cd 2#677, Crm Cd 3#678, Crm Cd 4#679, ... 10 more fields], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@11e6cf7b,StorageLevel(disk, memory, deserialized, 1 replicas),AdaptiveSparkPlan isFinalPlan=false
+- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields]
   +- BatchEvalPython [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]
      +- BroadcastNestedLoopJoin BuildRight, Cross
         :- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265 AS PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 5 more fields]
         :  +- Filter ((((((isnotnull(LAT#287) AND isnotnull(LON#288)) AND isnotnull(Weapon Used Cd#277)) AND NOT (LAT#287 = 0.0)) AND NOT (LON#288 = 0.0)) AND (Weapon Used Cd#277 >= 100)) AND (Weapon Used Cd#277 <= 199))
         :     +- FileScan csv [DR_NO#261,Date Rptd#262,DATE OCC#263,TIME OCC#264,AREA#265,AREA NAME#266,Rpt Dist No#267,Part 1-2#268,Crm Cd#269,Crm Cd Desc#270,Mocodes#271,Vict Age#272,Vict Sex#273,Vict Descent#274,Premis Cd#275,Premis Desc#276,Weapon Used Cd#277,Weapon Desc#278,Status#279,Status Desc#280,Crm Cd 1#281,Crm Cd 2#282,Crm Cd 3#283,Crm Cd 4#284,... 4 more fields] Batched: false, DataFilters: [isnotnull(LAT#287), isnotnull(LON#288), isnotnull(Weapon Used Cd#277), NOT (LAT#287 = 0.0), NOT ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LO..., ReadSchema: struct<DR_NO:int,Date Rptd:date,DATE OCC:date,TIME OCC:string,AREA:int,AREA NAME:string,Rpt Dist ...
         +- BroadcastExchange IdentityBroadcastMode, [plan_id=67]
            +- Project [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
               +- FileScan csv [X#0,Y#1,DIVISION#3,PREC#5] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>
,None)

(20) BroadcastExchange
Input [4]: [Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: IdentityBroadcastMode, [plan_id=119]

(21) BroadcastNestedLoopJoin
Join type: Cross
Join condition: None

(22) BatchEvalPython
Input [33]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]

(23) Project
Output [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, pythonUDF0#447 AS Distance to Station#412]
Input [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, pythonUDF0#447]

(24) AdaptiveSparkPlan
Output [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, Distance to Station#412]
Arguments: isFinalPlan=false

(25) Filter
Input [2]: [DR_NO#656, Distance to Station#412]
Condition : isnotnull(DR_NO#656)

(26) HashAggregate
Input [2]: [DR_NO#656, Distance to Station#412]
Keys [1]: [DR_NO#656]
Functions [1]: [partial_min(Distance to Station#412)]
Aggregate Attributes [1]: [min#1954]
Results [2]: [DR_NO#656, min#1955]

(27) Exchange
Input [2]: [DR_NO#656, min#1955]
Arguments: hashpartitioning(DR_NO#656, 200), ENSURE_REQUIREMENTS, [plan_id=204]

(28) HashAggregate
Input [2]: [DR_NO#656, min#1955]
Keys [1]: [DR_NO#656]
Functions [1]: [min(Distance to Station#412)]
Aggregate Attributes [1]: [min(Distance to Station#412)#652]
Results [2]: [DR_NO#656, min(Distance to Station#412)#652 AS Distance to Station#653]

(29) Filter
Input [2]: [DR_NO#656, Distance to Station#653]
Condition : isnotnull(Distance to Station#653)

(30) Exchange
Input [2]: [DR_NO#656, Distance to Station#653]
Arguments: hashpartitioning(DR_NO#656, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653)), 200), ENSURE_REQUIREMENTS, [plan_id=210]

(31) Sort
Input [2]: [DR_NO#656, Distance to Station#653]
Arguments: [DR_NO#656 ASC NULLS FIRST, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653)) ASC NULLS FIRST], false, 0

(32) SortMergeJoin
Left keys [2]: [DR_NO#261, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412))]
Right keys [2]: [DR_NO#656, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653))]
Join type: Inner
Join condition: None

(33) Project
Output [3]: [Year#318, Division#27, Distance to Station#412 AS Distance to Closest Station#726]
Input [6]: [DR_NO#261, Year#318, Division#27, Distance to Station#412, DR_NO#656, Distance to Station#653]

(34) AdaptiveSparkPlan
Output [3]: [Year#318, Division#27, Distance to Closest Station#726]
Arguments: isFinalPlan=false

(35) HashAggregate
Input [2]: [Year#318, Distance to Closest Station#726]
Keys [1]: [Year#318]
Functions [2]: [partial_avg(Distance to Closest Station#726), partial_count(1)]
Aggregate Attributes [3]: [sum#2138, count#2139L, count#2140L]
Results [4]: [Year#318, sum#2141, count#2142L, count#2143L]

(36) Exchange
Input [4]: [Year#318, sum#2141, count#2142L, count#2143L]
Arguments: hashpartitioning(Year#318, 200), ENSURE_REQUIREMENTS, [plan_id=198]

(37) HashAggregate
Input [4]: [Year#318, sum#2141, count#2142L, count#2143L]
Keys [1]: [Year#318]
Functions [2]: [avg(Distance to Closest Station#726), count(1)]
Aggregate Attributes [2]: [avg(Distance to Closest Station#726)#1974, count(1)#1976L]
Results [3]: [Year#318, avg(Distance to Closest Station#726)#1974 AS Average Distance to Closest Station#1975, count(1)#1976L AS ##1977L]

(38) Exchange
Input [3]: [Year#318, Average Distance to Closest Station#1975, ##1977L]
Arguments: rangepartitioning(Year#318 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=201]

(39) Sort
Input [3]: [Year#318, Average Distance to Closest Station#1975, ##1977L]
Arguments: [Year#318 ASC NULLS FIRST], true, 0

(40) AdaptiveSparkPlan
Output [3]: [Year#318, Average Distance to Closest Station#1975, ##1977L]
Arguments: isFinalPlan=false



[91mQ4: [00mQuery execution plan (2b, merge):
== Physical Plan ==
AdaptiveSparkPlan (40)
+- Sort (39)
   +- Exchange (38)
      +- HashAggregate (37)
         +- Exchange (36)
            +- HashAggregate (35)
               +- InMemoryTableScan (1)
                     +- InMemoryRelation (2)
                           +- AdaptiveSparkPlan (34)
                              +- Project (33)
                                 +- SortMergeJoin Inner (32)
                                    :- Sort (17)
                                    :  +- Exchange (16)
                                    :     +- Filter (15)
                                    :        +- InMemoryTableScan (3)
                                    :              +- InMemoryRelation (4)
                                    :                    +- AdaptiveSparkPlan (14)
                                    :                       +- Project (13)
                                    :                          +- BatchEvalPython (12)
                                    :                             +- BroadcastNestedLoopJoin Cross BuildRight (11)
                                    :                                :- Project (7)
                                    :                                :  +- Filter (6)
                                    :                                :     +- Scan csv  (5)
                                    :                                +- BroadcastExchange (10)
                                    :                                   +- Project (9)
                                    :                                      +- Scan csv  (8)
                                    +- Sort (31)
                                       +- Exchange (30)
                                          +- Filter (29)
                                             +- HashAggregate (28)
                                                +- Exchange (27)
                                                   +- HashAggregate (26)
                                                      +- Filter (25)
                                                         +- InMemoryTableScan (18)
                                                               +- InMemoryRelation (19)
                                                                     +- AdaptiveSparkPlan (24)
                                                                        +- Project (23)
                                                                           +- BatchEvalPython (22)
                                                                              +- BroadcastNestedLoopJoin Cross BuildRight (21)
                                                                                 :- Project (7)
                                                                                 :  +- Filter (6)
                                                                                 :     +- Scan csv  (5)
                                                                                 +- BroadcastExchange (20)
                                                                                    +- Project (9)
                                                                                       +- Scan csv  (8)


(1) InMemoryTableScan
Output [2]: [Division#27, Distance to Closest Station#726]
Arguments: [Division#27, Distance to Closest Station#726]

(2) InMemoryRelation
Arguments: [Year#318, Division#27, Distance to Closest Station#726], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@11e6cf7b,StorageLevel(disk, memory, deserialized, 1 replicas),AdaptiveSparkPlan isFinalPlan=false
+- Project [Year#318, Division#27, Distance to Station#412 AS Distance to Closest Station#726]
   +- SortMergeJoin [DR_NO#261, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412))], [DR_NO#656, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653))], Inner
      :- Sort [DR_NO#261 ASC NULLS FIRST, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412)) ASC NULLS FIRST], false, 0
      :  +- Exchange hashpartitioning(DR_NO#261, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412)), 200), ENSURE_REQUIREMENTS, [plan_id=107]
      :     +- Filter (isnotnull(DR_NO#261) AND isnotnull(Distance to Station#412))
      :        +- InMemoryTableScan [DR_NO#261, Year#318, Division#27, Distance to Station#412], [isnotnull(DR_NO#261), isnotnull(Distance to Station#412)]
      :              +- InMemoryRelation [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)
      :                    +- AdaptiveSparkPlan isFinalPlan=false
      :                       +- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields]
      :                          +- BatchEvalPython [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]
      :                             +- BroadcastNestedLoopJoin BuildRight, Cross
      :                                :- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265 AS PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 5 more fields]
      :                                :  +- Filter ((((((isnotnull(LAT#287) AND isnotnull(LON#288)) AND isnotnull(Weapon Used Cd#277)) AND NOT (LAT#287 = 0.0)) AND NOT (LON#288 = 0.0)) AND (Weapon Used Cd#277 >= 100)) AND (Weapon Used Cd#277 <= 199))
      :                                :     +- FileScan csv [DR_NO#261,Date Rptd#262,DATE OCC#263,TIME OCC#264,AREA#265,AREA NAME#266,Rpt Dist No#267,Part 1-2#268,Crm Cd#269,Crm Cd Desc#270,Mocodes#271,Vict Age#272,Vict Sex#273,Vict Descent#274,Premis Cd#275,Premis Desc#276,Weapon Used Cd#277,Weapon Desc#278,Status#279,Status Desc#280,Crm Cd 1#281,Crm Cd 2#282,Crm Cd 3#283,Crm Cd 4#284,... 4 more fields] Batched: false, DataFilters: [isnotnull(LAT#287), isnotnull(LON#288), isnotnull(Weapon Used Cd#277), NOT (LAT#287 = 0.0), NOT ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LO..., ReadSchema: struct<DR_NO:int,Date Rptd:date,DATE OCC:date,TIME OCC:string,AREA:int,AREA NAME:string,Rpt Dist ...
      :                                +- BroadcastExchange IdentityBroadcastMode, [plan_id=114]
      :                                   +- Project [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
      :                                      +- FileScan csv [X#0,Y#1,DIVISION#3,PREC#5] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>
      +- Sort [DR_NO#656 ASC NULLS FIRST, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653)) ASC NULLS FIRST], false, 0
         +- Exchange hashpartitioning(DR_NO#656, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653)), 200), ENSURE_REQUIREMENTS, [plan_id=108]
            +- Filter isnotnull(Distance to Station#653)
               +- HashAggregate(keys=[DR_NO#656], functions=[min(Distance to Station#412)], output=[DR_NO#656, Distance to Station#653])
                  +- Exchange hashpartitioning(DR_NO#656, 200), ENSURE_REQUIREMENTS, [plan_id=102]
                     +- HashAggregate(keys=[DR_NO#656], functions=[partial_min(Distance to Station#412)], output=[DR_NO#656, min#1955])
                        +- Filter isnotnull(DR_NO#656)
                           +- InMemoryTableScan [DR_NO#656, Distance to Station#412], [isnotnull(DR_NO#656)]
                                 +- InMemoryRelation [DR_NO#656, Date Rptd#657, DATE OCC#658, TIME OCC#659, PREC#348, AREA NAME#661, Rpt Dist No#662, Part 1-2#663, Crm Cd#664, Crm Cd Desc#665, Mocodes#666, Vict Age#667, Vict Sex#668, Vict Descent#669, Premis Cd#670, Premis Desc#671, Weapon Used Cd#672, Weapon Desc#673, Status#674, Status Desc#675, Crm Cd 1#676, Crm Cd 2#677, Crm Cd 3#678, Crm Cd 4#679, ... 10 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)
                                       +- AdaptiveSparkPlan isFinalPlan=false
                                          +- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields]
                                             +- BatchEvalPython [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]
                                                +- BroadcastNestedLoopJoin BuildRight, Cross
                                                   :- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265 AS PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 5 more fields]
                                                   :  +- Filter ((((((isnotnull(LAT#287) AND isnotnull(LON#288)) AND isnotnull(Weapon Used Cd#277)) AND NOT (LAT#287 = 0.0)) AND NOT (LON#288 = 0.0)) AND (Weapon Used Cd#277 >= 100)) AND (Weapon Used Cd#277 <= 199))
                                                   :     +- FileScan csv [DR_NO#261,Date Rptd#262,DATE OCC#263,TIME OCC#264,AREA#265,AREA NAME#266,Rpt Dist No#267,Part 1-2#268,Crm Cd#269,Crm Cd Desc#270,Mocodes#271,Vict Age#272,Vict Sex#273,Vict Descent#274,Premis Cd#275,Premis Desc#276,Weapon Used Cd#277,Weapon Desc#278,Status#279,Status Desc#280,Crm Cd 1#281,Crm Cd 2#282,Crm Cd 3#283,Crm Cd 4#284,... 4 more fields] Batched: false, DataFilters: [isnotnull(LAT#287), isnotnull(LON#288), isnotnull(Weapon Used Cd#277), NOT (LAT#287 = 0.0), NOT ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LO..., ReadSchema: struct<DR_NO:int,Date Rptd:date,DATE OCC:date,TIME OCC:string,AREA:int,AREA NAME:string,Rpt Dist ...
                                                   +- BroadcastExchange IdentityBroadcastMode, [plan_id=119]
                                                      +- Project [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
                                                         +- FileScan csv [X#0,Y#1,DIVISION#3,PREC#5] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>
,None)

(3) InMemoryTableScan
Output [4]: [DR_NO#261, Year#318, Division#27, Distance to Station#412]
Arguments: [DR_NO#261, Year#318, Division#27, Distance to Station#412], [isnotnull(DR_NO#261), isnotnull(Distance to Station#412)]

(4) InMemoryRelation
Arguments: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@11e6cf7b,StorageLevel(disk, memory, deserialized, 1 replicas),AdaptiveSparkPlan isFinalPlan=false
+- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields]
   +- BatchEvalPython [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]
      +- BroadcastNestedLoopJoin BuildRight, Cross
         :- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265 AS PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 5 more fields]
         :  +- Filter ((((((isnotnull(LAT#287) AND isnotnull(LON#288)) AND isnotnull(Weapon Used Cd#277)) AND NOT (LAT#287 = 0.0)) AND NOT (LON#288 = 0.0)) AND (Weapon Used Cd#277 >= 100)) AND (Weapon Used Cd#277 <= 199))
         :     +- FileScan csv [DR_NO#261,Date Rptd#262,DATE OCC#263,TIME OCC#264,AREA#265,AREA NAME#266,Rpt Dist No#267,Part 1-2#268,Crm Cd#269,Crm Cd Desc#270,Mocodes#271,Vict Age#272,Vict Sex#273,Vict Descent#274,Premis Cd#275,Premis Desc#276,Weapon Used Cd#277,Weapon Desc#278,Status#279,Status Desc#280,Crm Cd 1#281,Crm Cd 2#282,Crm Cd 3#283,Crm Cd 4#284,... 4 more fields] Batched: false, DataFilters: [isnotnull(LAT#287), isnotnull(LON#288), isnotnull(Weapon Used Cd#277), NOT (LAT#287 = 0.0), NOT ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LO..., ReadSchema: struct<DR_NO:int,Date Rptd:date,DATE OCC:date,TIME OCC:string,AREA:int,AREA NAME:string,Rpt Dist ...
         +- BroadcastExchange IdentityBroadcastMode, [plan_id=67]
            +- Project [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
               +- FileScan csv [X#0,Y#1,DIVISION#3,PREC#5] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>
,None)

(5) Scan csv 
Output [28]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288]
Batched: false
Location: InMemoryFileIndex [hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to_Present.csv]
PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0)), GreaterThanOrEqual(Weapon Used Cd,100), LessThanOrEqual(Weapon Used Cd,199)]
ReadSchema: struct<DR_NO:int,Date Rptd:date,DATE OCC:date,TIME OCC:string,AREA:int,AREA NAME:string,Rpt Dist No:int,Part 1-2:string,Crm Cd:int,Crm Cd Desc:string,Mocodes:string,Vict Age:int,Vict Sex:string,Vict Descent:string,Premis Cd:int,Premis Desc:string,Weapon Used Cd:int,Weapon Desc:string,Status:string,Status Desc:string,Crm Cd 1:int,Crm Cd 2:int,Crm Cd 3:int,Crm Cd 4:int,LOCATION:string,Cross Street:string,LAT:double,LON:double>

(6) Filter
Input [28]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288]
Condition : ((((((isnotnull(LAT#287) AND isnotnull(LON#288)) AND isnotnull(Weapon Used Cd#277)) AND NOT (LAT#287 = 0.0)) AND NOT (LON#288 = 0.0)) AND (Weapon Used Cd#277 >= 100)) AND (Weapon Used Cd#277 <= 199))

(7) Project
Output [29]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265 AS PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, year(Date Rptd#262) AS Year#318]
Input [28]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288]

(8) Scan csv 
Output [4]: [X#0, Y#1, DIVISION#3, PREC#5]
Batched: false
Location: InMemoryFileIndex [hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv]
ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>

(9) Project
Output [4]: [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
Input [4]: [X#0, Y#1, DIVISION#3, PREC#5]

(10) BroadcastExchange
Input [4]: [Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: IdentityBroadcastMode, [plan_id=114]

(11) BroadcastNestedLoopJoin
Join type: Cross
Join condition: None

(12) BatchEvalPython
Input [33]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]

(13) Project
Output [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, pythonUDF0#447 AS Distance to Station#412]
Input [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, pythonUDF0#447]

(14) AdaptiveSparkPlan
Output [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, Distance to Station#412]
Arguments: isFinalPlan=false

(15) Filter
Input [4]: [DR_NO#261, Year#318, Division#27, Distance to Station#412]
Condition : (isnotnull(DR_NO#261) AND isnotnull(Distance to Station#412))

(16) Exchange
Input [4]: [DR_NO#261, Year#318, Division#27, Distance to Station#412]
Arguments: hashpartitioning(DR_NO#261, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412)), 200), ENSURE_REQUIREMENTS, [plan_id=241]

(17) Sort
Input [4]: [DR_NO#261, Year#318, Division#27, Distance to Station#412]
Arguments: [DR_NO#261 ASC NULLS FIRST, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412)) ASC NULLS FIRST], false, 0

(18) InMemoryTableScan
Output [2]: [DR_NO#656, Distance to Station#412]
Arguments: [DR_NO#656, Distance to Station#412], [isnotnull(DR_NO#656)]

(19) InMemoryRelation
Arguments: [DR_NO#656, Date Rptd#657, DATE OCC#658, TIME OCC#659, PREC#348, AREA NAME#661, Rpt Dist No#662, Part 1-2#663, Crm Cd#664, Crm Cd Desc#665, Mocodes#666, Vict Age#667, Vict Sex#668, Vict Descent#669, Premis Cd#670, Premis Desc#671, Weapon Used Cd#672, Weapon Desc#673, Status#674, Status Desc#675, Crm Cd 1#676, Crm Cd 2#677, Crm Cd 3#678, Crm Cd 4#679, ... 10 more fields], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@11e6cf7b,StorageLevel(disk, memory, deserialized, 1 replicas),AdaptiveSparkPlan isFinalPlan=false
+- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 10 more fields]
   +- BatchEvalPython [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]
      +- BroadcastNestedLoopJoin BuildRight, Cross
         :- Project [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, AREA#265 AS PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, ... 5 more fields]
         :  +- Filter ((((((isnotnull(LAT#287) AND isnotnull(LON#288)) AND isnotnull(Weapon Used Cd#277)) AND NOT (LAT#287 = 0.0)) AND NOT (LON#288 = 0.0)) AND (Weapon Used Cd#277 >= 100)) AND (Weapon Used Cd#277 <= 199))
         :     +- FileScan csv [DR_NO#261,Date Rptd#262,DATE OCC#263,TIME OCC#264,AREA#265,AREA NAME#266,Rpt Dist No#267,Part 1-2#268,Crm Cd#269,Crm Cd Desc#270,Mocodes#271,Vict Age#272,Vict Sex#273,Vict Descent#274,Premis Cd#275,Premis Desc#276,Weapon Used Cd#277,Weapon Desc#278,Status#279,Status Desc#280,Crm Cd 1#281,Crm Cd 2#282,Crm Cd 3#283,Crm Cd 4#284,... 4 more fields] Batched: false, DataFilters: [isnotnull(LAT#287), isnotnull(LON#288), isnotnull(Weapon Used Cd#277), NOT (LAT#287 = 0.0), NOT ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/Crime_Data_from_2010_to..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), IsNotNull(Weapon Used Cd), Not(EqualTo(LAT,0.0)), Not(EqualTo(LO..., ReadSchema: struct<DR_NO:int,Date Rptd:date,DATE OCC:date,TIME OCC:string,AREA:int,AREA NAME:string,Rpt Dist ...
         +- BroadcastExchange IdentityBroadcastMode, [plan_id=67]
            +- Project [X#0 AS Station LON#12, Y#1 AS Station LAT#20, DIVISION#3 AS Division#27, PREC#5]
               +- FileScan csv [X#0,Y#1,DIVISION#3,PREC#5] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/user/user/datasets/LAPD_Police_Stations.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,DIVISION:string,PREC:int>
,None)

(20) BroadcastExchange
Input [4]: [Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: IdentityBroadcastMode, [plan_id=119]

(21) BroadcastNestedLoopJoin
Join type: Cross
Join condition: None

(22) BatchEvalPython
Input [33]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5]
Arguments: [<lambda>(LAT#287, LON#288, Station LAT#20, Station LON#12)#411], [pythonUDF0#447]

(23) Project
Output [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, pythonUDF0#447 AS Distance to Station#412]
Input [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, pythonUDF0#447]

(24) AdaptiveSparkPlan
Output [34]: [DR_NO#261, Date Rptd#262, DATE OCC#263, TIME OCC#264, PREC#348, AREA NAME#266, Rpt Dist No#267, Part 1-2#268, Crm Cd#269, Crm Cd Desc#270, Mocodes#271, Vict Age#272, Vict Sex#273, Vict Descent#274, Premis Cd#275, Premis Desc#276, Weapon Used Cd#277, Weapon Desc#278, Status#279, Status Desc#280, Crm Cd 1#281, Crm Cd 2#282, Crm Cd 3#283, Crm Cd 4#284, LOCATION#285, Cross Street#286, LAT#287, LON#288, Year#318, Station LON#12, Station LAT#20, Division#27, PREC#5, Distance to Station#412]
Arguments: isFinalPlan=false

(25) Filter
Input [2]: [DR_NO#656, Distance to Station#412]
Condition : isnotnull(DR_NO#656)

(26) HashAggregate
Input [2]: [DR_NO#656, Distance to Station#412]
Keys [1]: [DR_NO#656]
Functions [1]: [partial_min(Distance to Station#412)]
Aggregate Attributes [1]: [min#1954]
Results [2]: [DR_NO#656, min#1955]

(27) Exchange
Input [2]: [DR_NO#656, min#1955]
Arguments: hashpartitioning(DR_NO#656, 200), ENSURE_REQUIREMENTS, [plan_id=236]

(28) HashAggregate
Input [2]: [DR_NO#656, min#1955]
Keys [1]: [DR_NO#656]
Functions [1]: [min(Distance to Station#412)]
Aggregate Attributes [1]: [min(Distance to Station#412)#652]
Results [2]: [DR_NO#656, min(Distance to Station#412)#652 AS Distance to Station#653]

(29) Filter
Input [2]: [DR_NO#656, Distance to Station#653]
Condition : isnotnull(Distance to Station#653)

(30) Exchange
Input [2]: [DR_NO#656, Distance to Station#653]
Arguments: hashpartitioning(DR_NO#656, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653)), 200), ENSURE_REQUIREMENTS, [plan_id=242]

(31) Sort
Input [2]: [DR_NO#656, Distance to Station#653]
Arguments: [DR_NO#656 ASC NULLS FIRST, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653)) ASC NULLS FIRST], false, 0

(32) SortMergeJoin
Left keys [2]: [DR_NO#261, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#412))]
Right keys [2]: [DR_NO#656, knownfloatingpointnormalized(normalizenanandzero(Distance to Station#653))]
Join type: Inner
Join condition: None

(33) Project
Output [3]: [Year#318, Division#27, Distance to Station#412 AS Distance to Closest Station#726]
Input [6]: [DR_NO#261, Year#318, Division#27, Distance to Station#412, DR_NO#656, Distance to Station#653]

(34) AdaptiveSparkPlan
Output [3]: [Year#318, Division#27, Distance to Closest Station#726]
Arguments: isFinalPlan=false

(35) HashAggregate
Input [2]: [Division#27, Distance to Closest Station#726]
Keys [1]: [Division#27]
Functions [2]: [partial_avg(Distance to Closest Station#726), partial_count(1)]
Aggregate Attributes [3]: [sum#2189, count#2190L, count#2191L]
Results [4]: [Division#27, sum#2192, count#2193L, count#2194L]

(36) Exchange
Input [4]: [Division#27, sum#2192, count#2193L, count#2194L]
Arguments: hashpartitioning(Division#27, 200), ENSURE_REQUIREMENTS, [plan_id=230]

(37) HashAggregate
Input [4]: [Division#27, sum#2192, count#2193L, count#2194L]
Keys [1]: [Division#27]
Functions [2]: [avg(Distance to Closest Station#726), count(1)]
Aggregate Attributes [2]: [avg(Distance to Closest Station#726)#1984, count(1)#1986L]
Results [3]: [Division#27, avg(Distance to Closest Station#726)#1984 AS Average Distance to Closest Station#1985, count(1)#1986L AS ##1987L]

(38) Exchange
Input [3]: [Division#27, Average Distance to Closest Station#1985, ##1987L]
Arguments: rangepartitioning(##1987L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=233]

(39) Sort
Input [3]: [Division#27, Average Distance to Closest Station#1985, ##1987L]
Arguments: [##1987L DESC NULLS LAST], true, 0

(40) AdaptiveSparkPlan
Output [3]: [Division#27, Average Distance to Closest Station#1985, ##1987L]
Arguments: isFinalPlan=false


